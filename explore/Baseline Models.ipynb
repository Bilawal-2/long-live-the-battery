{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models and Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook adapts the feature engineering from the original paper to our windowed approach.  We use linear & other simple regression models here to serve as a baseline for the deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/rebuild_windowed_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1_2_keys = df['cell_key'][df['cell_batch']!=3].unique()\n",
    "train_keys = batch_1_2_keys[1::2]\n",
    "test_keys = batch_1_2_keys[0::2]\n",
    "train_ind = df[df['cell_key'].isin(train_keys)].index\n",
    "test_ind = df[df['cell_key'].isin(test_keys)].index\n",
    "secondary_test_ind = df[df['cell_batch']==3].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature and target columns for regression models\n",
    "\n",
    "varmod_features = [\"variance_dQ_window\"]\n",
    "dismod_features = [\n",
    "    \"variance_dQ_window\",\n",
    "    \"minimum_dQ_window\",\n",
    "    \"skewness_dQ_window\",\n",
    "    \"kurtosis_dQ_window\",\n",
    "    \"discharge_capacity_1\",\n",
    "    \"diff_discharge_capacity_max_1\",\n",
    "]\n",
    "fullmod_features = [\n",
    "    \"minimum_dQ_window\",\n",
    "    \"variance_dQ_window\",\n",
    "    \"slope_lin_fit_window\",\n",
    "    \"intercept_lin_fit_window\",\n",
    "    \"discharge_capacity_1\",\n",
    "    \"mean_discharge_time\",\n",
    "    \"minimum_IR_window\",\n",
    "    \"diff_IR_window\",\n",
    "]\n",
    "targetmod = [\"target_remaining\"]  # , \"target_current\"\n",
    "\n",
    "# Define feature and target columns for classifiers\n",
    "\n",
    "varclf_features = [\"variance_dQ_window\"]\n",
    "fullclf_features = [\n",
    "    \"minimum_dQ_window\",\n",
    "    \"variance_dQ_window\",\n",
    "    \"discharge_capacity_1\",\n",
    "    \"diff_IR_window\",\n",
    "]\n",
    "targetclf = [\"target_classifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(data, features, target, split):\n",
    "    X = data.iloc[split,:].loc[:,features]\n",
    "    y = data.iloc[split,:].loc[:,target]\n",
    "    return X, y\n",
    "\n",
    "def eval_model(model, data, features, target, split):\n",
    "    rmse = list()\n",
    "    mpe = list()\n",
    "    for split in splits:\n",
    "        X, y = get_split(data, features, target, split)\n",
    "        pred = model.predict(X)\n",
    "        rmse.append(np.sqrt(mean_squared_error(pred, y)))\n",
    "        mpe.append(float(np.mean(np.abs((y - pred.reshape(-1,1))) / y * 100)))\n",
    "    return rmse, mpe\n",
    "\n",
    "def eval_classifier(model, data, features, target, splits):\n",
    "    acc = list()    \n",
    "    for split in splits:\n",
    "        X, y = get_split(data, features, target, split)\n",
    "        pred = model.predict(X)\n",
    "        acc.append(accuracy_score(pred, y.values.ravel()))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Elastic net\n",
    "x_train, y_train = get_split(df, varmod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.0001,1,30)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.01, 0.25, 0.5, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state=54)\n",
    "regr = GridSearchCV(enet, parameters, cv=4, iid=False)\n",
    "print(\"Elastic Net: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "\"\"\"\n",
    "Because an elastic net with alpha = 0 is technically a linear regression\n",
    "and elastic net produces inaccuracies with a small alpha,\n",
    "we also train a linear regression model.\n",
    "Linear regression performs slighty better at RMSE,\n",
    "Elastic net performs slightly better at MPE.\n",
    "We decide to take the linear regression scores.\n",
    "\"\"\"\n",
    "lin_reg = LinearRegression()\n",
    "print(\"Linear Regression: %s\" % lin_reg.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "varmod_rmse, varmod_mpe = eval_model(lin_reg, df, varmod_features, targetmod, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discharge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Elastic net\n",
    "x_train, y_train = get_split(df, dismod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.1,1,20)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.01, 0.25, 0.5, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state=54)\n",
    "regr = GridSearchCV(enet, parameters, cv=4, iid=False)\n",
    "print(\"Elastic Net: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "dismod_rmse, dismod_mpe = eval_model(regr, df, dismod_features, targetmod, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train Elastic net model\n",
    "# raising the alpha minimum to 0.59 silences the convergence warnings,\n",
    "# but decreases the score significantly - what's wrong here? \n",
    "\n",
    "x_train, y_train = get_split(df, fullmod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.001,1,20)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.001, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state=54)\n",
    "regr = GridSearchCV(enet, parameters, cv=4, iid=False)\n",
    "print(\"Elastic Net: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "fullmod_rmse, fullmod_mpe = eval_model(regr, df, fullmod_features, targetmod, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate all linear regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Model\":[\"Variance model\", \"Discharge model\", \"Full model\"],\n",
    "              \"RMSE - Train\": [varmod_rmse[0],dismod_rmse[0],fullmod_rmse[0]],\n",
    "              \"RMSE - Primary test\": [varmod_rmse[1],dismod_rmse[1],fullmod_rmse[1]],\n",
    "              \"RMSE - Secondary test\": [varmod_rmse[2],dismod_rmse[2],fullmod_rmse[2]],\n",
    "              \"MPE - Train\": [varmod_mpe[0],dismod_mpe[0],fullmod_mpe[0]],\n",
    "              \"MPE - Primary test\": [varmod_mpe[1],dismod_mpe[1],fullmod_mpe[1]],\n",
    "              \"MPE - Secondary test\": [varmod_mpe[2],dismod_mpe[2],fullmod_mpe[2]]})                                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "x_train, y_train = get_split(df, varclf_features, targetclf, train_ind)\n",
    "\n",
    "parameters = {\"C\": [0.01,0.1,0.5,0.75,1]}\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\", random_state=54)\n",
    "clf = GridSearchCV(logreg, parameters, cv=4, iid=False)\n",
    "print(\"Logreg: %s\" % clf.fit(x_train, y_train.values.ravel()).score(x_train, y_train.values.ravel()))\n",
    "\n",
    "varclf_acc = eval_classifier(clf, df, varclf_features, targetclf, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "# Why is the full classifier worse than the variance classifier?\n",
    "x_train, y_train = get_split(df, fullclf_features, targetclf, train_ind)\n",
    "\n",
    "parameters = {\"C\": [0.01,0.1,0.5,0.75,1]}\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\", random_state=54)\n",
    "clf = GridSearchCV(logreg, parameters, cv=4, iid=False)\n",
    "print(\"Logreg: %s\" % clf.fit(x_train, y_train.values.ravel()).score(x_train, y_train.values.ravel()))\n",
    "\n",
    "fullclf_acc = eval_classifier(clf, df, fullclf_features, targetclf, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Classifier\":[\"Variance classifier\", \"Full classifier\"],\n",
    "              \"Acc - Train\": [varclf_acc[0],fullclf_acc[0]],\n",
    "              \"Acc - Primary test\": [varclf_acc[1],fullclf_acc[1]],\n",
    "              \"Acc - Secondary test\": [varclf_acc[2],fullclf_acc[2]]})                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
