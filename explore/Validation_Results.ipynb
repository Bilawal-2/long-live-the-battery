{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change working directory to base, to make all imports and file paths work\n",
    "import os\n",
    "os.chdir(os.pardir)\n",
    "print(\"Current directory: %s\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainer.data_pipeline as dp\n",
    "import trainer.constants as cst\n",
    "from trainer.helpers import print_dict_keys, simple_plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that saved_model has been created with the same version of TensorFlow\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"data/ion_age_20190614_205447/saved_model\"\n",
    "dataset_dir = cst.TEST_SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.experimental.load_from_saved_model(model_dir)\n",
    "\n",
    "# To look at available model methods:\n",
    "# list(method for method in dir(model) if not method.startswith(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapes = {k: v for k, v in zip(model.input_names, model.input_shape)}\n",
    "input_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with dataset\n",
    "window_size = 20\n",
    "shift = 20\n",
    "stride = 1\n",
    "batch_size = 16\n",
    "\n",
    "dataset = dp.create_dataset(dataset_dir,\n",
    "                            window_size=window_size,\n",
    "                            shift=shift,  # Can vary during validation\n",
    "                            stride=stride,\n",
    "                            batch_size=batch_size,  # Can vary during validation\n",
    "                            cycle_length=1,  # To match original order (so no files get interleaved)\n",
    "                            num_parallel_calls=1,  # Has to be equal or below cycle_length\n",
    "                            shuffle=False,  # To match original order\n",
    "                            repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factors = dp.load_scaling_factors()\n",
    "scaling_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "for i , (example, target) in enumerate(dataset):\n",
    "    predictions.extend(model.predict(example).tolist())\n",
    "    targets.extend(target.numpy().tolist())\n",
    "\n",
    "predictions = np.array(predictions) * scaling_factors[cst.REMAINING_CYCLES_NAME]\n",
    "targets = np.array(targets) * scaling_factors[cst.REMAINING_CYCLES_NAME]\n",
    "results = pd.DataFrame({\n",
    "    \"pred_current_cycle\": predictions[:, 0],\n",
    "    \"pred_remaining_cycles\": predictions[:, 1],\n",
    "    \"target_current_cycle\": targets[:, 0],\n",
    "    \"target_remaining_cycles\": targets[:, 1],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"ae_current_cycle\"] = (results[\"pred_current_cycle\"] - results[\"target_current_cycle\"]).abs()\n",
    "results[\"ae_remaining_cycles\"] = (results[\"pred_remaining_cycles\"] - results[\"target_remaining_cycles\"]).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results.hist(bins=100, figsize=(15, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_plotly(np.arange(len(results)),\n",
    "              pred_remaining=results[\"pred_remaining_cycles\"],\n",
    "              target_remaining=results[\"target_remaining_cycles\"])\n",
    "\n",
    "# TODO:\n",
    "\"\"\"\n",
    "TODO\n",
    "    Output relu\n",
    "    Absoliute error over all cells\n",
    "    Feature values over all cells and windows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(results[\"pred_remaining_cycles\"] - results[\"target_remaining_cycles\"]).abs().hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.IntervalIndex.from_tuples([(-np.inf, 100), (100, 1000), (1000, np.inf)])\n",
    "binning = pd.cut(results[\"target_remaining_cycles\"], bins=bins)\n",
    "\n",
    "binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.hist(bins=50, figsize=(15, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_pkl = dp.load_processed_battery_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_current_cycle = [float(k) / scaling_factors[cst.REMAINING_CYCLES_NAME] for k in preprocessed_pkl[\"b1c0\"][\"cycles\"].keys()]\n",
    "target_current_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, (cell_k, cell_v) in enumerate(preprocessed_pkl.items()):\n",
    "    if i == 1:\n",
    "        break\n",
    "    cycle_keys = list(cell_v[\"cycles\"].keys())\n",
    "\n",
    "    window_cycle_keys = []\n",
    "    for i, w_slice in enumerate(range(0, len(cycle_keys), shift)):\n",
    "        cycle_keys_slice = cycle_keys[w_slice:w_slice + window_size]\n",
    "        if len(cycle_keys_slice) % window_size == 0:  # drop remainder\n",
    "            window_cycle_keys.append(cycle_keys_slice)\n",
    "    \n",
    "    assert np.all([len(w) == window_size for w in window_cycle_keys]), \\\n",
    "        \"Not all windows have the correct window_size\"\n",
    "    print(\"Number of windows in '{}': {}\".format(cell_k, len(window_cycle_keys)))\n",
    "    #print(window_cycle_keys)\n",
    "    for j, (w_cycle_keys, example) in enumerate(zip(window_cycle_keys, dataset)):  # Iterate over all windows\n",
    "        if j == 3:\n",
    "            break\n",
    "        print(\"\\n##### Window {} #####\".format(j))\n",
    "        \n",
    "        # Dataset values\n",
    "        print(\"Example shapes:\", {k:v.shape for k, v in example[0].items()})\n",
    "        print(\"\\nDataset Target:\", example[1].numpy())\n",
    "        # Processed Values\n",
    "        processed_target = cell_v[\"summary\"][cst.REMAINING_CYCLES_NAME] \\\n",
    "                                / scaling_factors[cst.REMAINING_CYCLES_NAME]\n",
    "        #print(\"Processed Target:\", processed_target[(window_size + stride * j)])\n",
    "        for z, k in enumerate(w_cycle_keys):  # Itereate over all strides\n",
    "            print(\"\\n# Step\")\n",
    "            scaled = example[0][cst.QDLIN_NAME][:, z, :, :].numpy().squeeze() * scaling_factors[cst.QDLIN_NAME]\n",
    "            print(scaled.shape)\n",
    "            processed = cell_v[\"cycles\"][k][cst.QDLIN_NAME].squeeze()\n",
    "            print(processed.shape)\n",
    "            print(\"Num close:, \", np.sum(np.isclose(scaled, processed, atol=1e-8)))\n",
    "            processed_rc = (cell_v[\"summary\"][cst.REMAINING_CYCLES_NAME][z + j * (window_size - stride)] \\\n",
    "                                / scaling_factors[cst.REMAINING_CYCLES_NAME]).astype(np.float32)\n",
    "            print(processed_rc)\n",
    "            print(cell_v[\"summary\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleInformer:\n",
    "    \n",
    "    def __init__(self, processed_data_pkl, window_size, shift, stride, batch_size):\n",
    "        self.processed_data_pkl = processed_data_pkl\n",
    "        self.window_size = window_size,\n",
    "        self.shift = shift,\n",
    "        self.stride = stride,\n",
    "        self.batch_size = batch_size\n",
    "        self.example_info = None\n",
    "    \n",
    "    def _generate_example_info(self):\n",
    "        self.example_info = None\n",
    "    \n",
    "    def get_example_info(example_number):\n",
    "        return example_info\n",
    "    \n",
    "    def _check_if_close():\n",
    "        pass\n",
    "    \n",
    "    def get_preprocessed_data_from_info(example_info):\n",
    "        # TODO\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (example, target) in enumerate(dataset.take(4)):\n",
    "    target_cc = target.numpy()[0][0]\n",
    "    preprocessed_target_cc = np.array(target_current_cycle)\n",
    "    close_mask = np.isclose(target_cc, preprocessed_target_cc)\n",
    "    print(target_cc)\n",
    "    print(preprocessed_target_cc[close_mask][0])\n",
    "    print(np.argwhere(close_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dict_keys(preprocessed_pkl[\"b1c1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
